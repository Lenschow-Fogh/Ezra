{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# LOAD CLASS AND DATASET \r\n",
    "# dataset: https://www.kaggle.com/rmisra/news-category-dataset\r\n",
    "# start:    each doc in corpus contains an article link, category and other (irrelevant) key/value pairs\r\n",
    "# end goal: each doc in corpus contains a sentence with POS tagging and gender polarity, and label vector with actual gender\r\n",
    "%reload_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "from classes.data_prepper import DataPrepper\r\n",
    "\r\n",
    "p = DataPrepper()\r\n",
    "\r\n",
    "data = p.load_json('datasets/1_newsDataset.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "constructor of DataPrepper\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# FILTER CATEGORIES\r\n",
    "\r\n",
    "men_categories = ['SPORTS', 'MONEY', 'BUSINESS']\r\n",
    "women_categories = ['WOMEN', 'STYLE & BEAUTY']\r\n",
    "\r\n",
    "data['articles'] = p.filter_articles(men_categories+women_categories, data['articles'])\r\n",
    "\r\n",
    "p.write_json('datasets/2_filtered_news_data.json', data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# SCRAPE LINKS\r\n",
    "\r\n",
    "# scraped_data = {}\r\n",
    "# scraped_data['articles'] = []\r\n",
    "# textlessUrls = []\r\n",
    "\r\n",
    "# for article in data['articles']:\r\n",
    "#     text = p.scrape_url(article['link'], textlessUrls)\r\n",
    "#     gender = 'M' if article['category'] in men_categories else 'W'\r\n",
    "#     if text != \"\":\r\n",
    "#         scraped_data['articles'].append({'gender': gender, 'text': text})\r\n",
    "\r\n",
    "# p.write_json('datasets/3_text_and_gender.json', scraped_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# INSTANTIATE NLP FROM SPACY\r\n",
    "import spacy\r\n",
    "\r\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "scraped_data = p.load_json('datasets/3_text_and_gender.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# CALCULATE WEIGHTS FOR EACH TERM\r\n",
    "# using tf-idf weighting from 'An Introduction to Information Retrieval (2009 Online Edition)'\r\n",
    "# written by Christopher D. Manning, Prabhakar Raghavan & Hinrich Sch√ºtze\r\n",
    "ignore_terms = ['.', ',', '...', ' ', '\\u2019', '  ', '(', ')', '?', '\\u00a3', '/', '\"', ':', ';', '-', '--', '\\u2015', \"'\", '!', '$', '#', '\\u2014', '   ', '[',']']\r\n",
    "ignore_ents = ['TIME', 'DATE', 'GPE', 'CARDINAL', 'PERSON', 'MONEY', 'PERCENT']\r\n",
    "\r\n",
    "m_weights, w_weights = p.get_weights(scraped_data['articles'], nlp, ignore_terms, ignore_ents)\r\n",
    "\r\n",
    "p.write_json('datasets/4_word_weight_m.json', m_weights)\r\n",
    "p.write_json('datasets/4_word_weight_w.json', w_weights)\r\n",
    "\r\n",
    "p.write_json('datasets/4_word_weight_m.json', p.order_dict(m_weights, 'desc'))\r\n",
    "p.write_json('datasets/4_word_weight_w.json', p.order_dict(w_weights, 'desc'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# CALCULATE POLARITY FOR EACH TERM\r\n",
    "# -1 (man) to 1 (woman)\r\n",
    "\r\n",
    "polarity_dict = p.get_polarity(w_weights, m_weights)\r\n",
    "p.write_json('datasets/5_word_polarity.json', polarity_dict)\r\n",
    "p.write_json('datasets/5_word_polarity_ordered.json', p.order_dict(polarity_dict, 'desc'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# WRAP ALL INTO FINAL DATASET\r\n",
    "# split all texts into sentences into words, each assigned sentence #, word, lemma, pos, dep and polarity\r\n",
    "import json\r\n",
    "\r\n",
    "data = p.load_json('datasets/3_text_and_gender.json')\r\n",
    "corpus =    {\r\n",
    "                'X': [], \r\n",
    "                'label': []\r\n",
    "            }\r\n",
    "# corpus['X'].append({'Sentence #', 'Word', 'Lemma', 'POS', 'Tag', 'Dep', 'Polarity'})\r\n",
    "# corpus['label'].append({'Gender'})\r\n",
    "\r\n",
    "for article in data['articles']:\r\n",
    "    doc = nlp(article['text'])\r\n",
    "    assert doc.has_annotation(\"SENT_START\")\r\n",
    "    for sent in doc.sents:\r\n",
    "        for token in sent:\r\n",
    "            corpus['X'].append({\r\n",
    "                'sentence': 1, \r\n",
    "                'word': token.text, \r\n",
    "                'lemma': token.lemma_, \r\n",
    "                'pos': token.pos_, \r\n",
    "                'dep': token.dep_, \r\n",
    "                'polarity': polarity_dict[token.lemma_] if token.lemma_ in polarity_dict else 0})\r\n",
    "            corpus['label'].append({'gender': article['gender']})\r\n",
    "\r\n",
    "with open('../datasets/6_dataset.json', \"w\") as outFile:\r\n",
    "    json.dump(corpus, outFile)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "5ce0bbaaba556c243eee45087b7684ce43fda2aa9a5b0798832d1be21bf73af7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}