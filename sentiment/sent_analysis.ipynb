{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# LOAD CLASS AND DATASET \r\n",
    "# dataset: https://www.kaggle.com/rmisra/news-category-dataset\r\n",
    "# start:    each doc in corpus contains an article link, category and other (irrelevant) key/value pairs\r\n",
    "# end goal: each doc in corpus contains a sentence with POS tagging and gender polarity, and label vector with actual gender\r\n",
    "%reload_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "from classes.data_prepper import DataPrepper\r\n",
    "\r\n",
    "p = DataPrepper()\r\n",
    "\r\n",
    "data = p.load_json('datasets/1_newsDataset.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "constructor of DataPrepper\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# FILTER CATEGORIES\r\n",
    "\r\n",
    "men_categories = ['SPORTS', 'MONEY', 'BUSINESS']\r\n",
    "women_categories = ['WOMEN', 'STYLE & BEAUTY']\r\n",
    "\r\n",
    "data['articles'] = p.filter_articles(men_categories+women_categories, data['articles'])\r\n",
    "\r\n",
    "p.write_json('datasets/2_filtered_news_data.json', data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# SCRAPE LINKS\r\n",
    "\r\n",
    "scraped_data = {}\r\n",
    "scraped_data['articles'] = []\r\n",
    "textlessUrls = []\r\n",
    "\r\n",
    "for article in data['articles']:\r\n",
    "    text = p.scrape_url(article['link'], textlessUrls)\r\n",
    "    gender = 'M' if article['category'] in men_categories else 'W'\r\n",
    "    if text != \"\":\r\n",
    "        scraped_data['articles'].append({'gender': gender, 'text': text})\r\n",
    "\r\n",
    "p.write_json('datasets/3_text_and_gender.json', scraped_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# INSTANTIATE NLP FROM SPACY\r\n",
    "import spacy\r\n",
    "\r\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# CALCULATE WEIGHTS FOR EACH TERM\r\n",
    "# using tf-idf weighting from 'An Introduction to Information Retrieval (2009 Online Edition)'\r\n",
    "# written by Christopher D. Manning, Prabhakar Raghavan & Hinrich Schütze\r\n",
    "ignore_terms = ['.', ',', '...', ' ', '\\u2019', '  ', '(', ')', '?', '\\u00a3', '/', '\"', ':', ';', '-', '--', '\\u2015', \"'\", '!', '$', '#', '\\u2014', '   ', '[',']']\r\n",
    "ignore_ents = ['TIME', 'DATE', 'GPE', 'CARDINAL', 'PERSON', 'MONEY', 'PERCENT']\r\n",
    "\r\n",
    "m_weights, w_weights = p.get_weights(scraped_data['articles'], nlp, ignore_terms, ignore_ents)\r\n",
    "\r\n",
    "p.write_json('datasets/4_word_weight_m.json', m_weights)\r\n",
    "p.write_json('datasets/4_word_weight_w.json', w_weights)\r\n",
    "\r\n",
    "p.write_json('datasets/4_word_weight_m_ordered.json', p.order_dict(m_weights, 'desc'))\r\n",
    "p.write_json('datasets/4_word_weight_w_ordered.json', p.order_dict(w_weights, 'desc'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# NORMALIZE WEIGHTS\r\n",
    "\r\n",
    "p.normalize_dict(m_weights)\r\n",
    "p.normalize_dict(w_weights)\r\n",
    "\r\n",
    "p.write_json('datasets/5_word_weight_m_norm.json', m_weights)\r\n",
    "p.write_json('datasets/5_word_weight_w_norm.json', w_weights)\r\n",
    "\r\n",
    "p.write_json('datasets/5_word_weight_m_norm_ordered.json', p.order_dict(m_weights, 'desc'))\r\n",
    "p.write_json('datasets/5_word_weight_w_norm_ordered.json', p.order_dict(w_weights, 'desc'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# CALCULATE POLARITY FOR EACH TERM\r\n",
    "# -1 (man) to 1 (woman)\r\n",
    "\r\n",
    "polarity_dict = p.get_polarity(w_weights, m_weights)\r\n",
    "p.write_json('datasets/6_word_polarity.json', polarity_dict)\r\n",
    "p.write_json('datasets/6_word_polarity_ordered.json', p.order_dict(polarity_dict, 'desc'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# WRAP ALL INTO FINAL DATASET\r\n",
    "# split all texts into sentences into words, each assigned sentence #, word, lemma, pos, dep and polarity\r\n",
    "# runtime: ~31 min\r\n",
    "import json\r\n",
    "\r\n",
    "data = p.load_json('datasets/3_text_and_gender.json')\r\n",
    "polarity_dict = p.load_json('datasets/6_word_polarity.json')\r\n",
    "\r\n",
    "corpus =    {\r\n",
    "                'Sentence #': [], \r\n",
    "                'Word': [],\r\n",
    "                'Lemma': [],\r\n",
    "                'POS': [],\r\n",
    "                'Tag': [],\r\n",
    "                'Dep': [],\r\n",
    "                'Polarity': [],\r\n",
    "                'Label': []\r\n",
    "            }\r\n",
    "# corpus['X'].append({'Sentence #', 'Word', 'Lemma', 'POS', 'Tag', 'Dep', 'Polarity'})\r\n",
    "# corpus['label'].append({'Gender'})\r\n",
    "\r\n",
    "for i, article in enumerate(data['articles']):\r\n",
    "    doc = nlp(article['text'])\r\n",
    "    assert doc.has_annotation(\"SENT_START\")\r\n",
    "    for sent in doc.sents:\r\n",
    "        for token in sent:\r\n",
    "            corpus['Sentence #'].append(i)\r\n",
    "            corpus['Word'].append(token.text)\r\n",
    "            corpus['Lemma'].append(token.lemma_)\r\n",
    "            corpus['POS'].append(token.pos_)\r\n",
    "            corpus['Tag'].append(token.tag_)\r\n",
    "            corpus['Dep'].append(token.dep_)\r\n",
    "            corpus['Polarity'].append(polarity_dict[token.lemma_] if token.lemma_ in polarity_dict else 0)\r\n",
    "            corpus['Label'].append(article['gender'])\r\n",
    "\r\n",
    "with open('datasets/7_dataset.json', \"w\") as outFile:\r\n",
    "    json.dump(corpus, outFile)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# LOAD DATASET WITH PANDA \r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "df = pd.read_json('datasets/7_dataset.json')\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Dep</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>At</td>\n",
       "      <td>at</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>least</td>\n",
       "      <td>least</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RBS</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nummod</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>organizations</td>\n",
       "      <td>organization</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>-0.193345</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>aux</td>\n",
       "      <td>-0.046438</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209400</th>\n",
       "      <td>23310</td>\n",
       "      <td>spot</td>\n",
       "      <td>spot</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>-0.001930</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209401</th>\n",
       "      <td>23310</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209402</th>\n",
       "      <td>23310</td>\n",
       "      <td>Howard</td>\n",
       "      <td>Howard</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209403</th>\n",
       "      <td>23310</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209404</th>\n",
       "      <td>23310</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13209405 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence #           Word         Lemma    POS  Tag     Dep  \\\n",
       "0                  0             At            at    ADV   RB  advmod   \n",
       "1                  0          least         least    ADV  RBS  advmod   \n",
       "2                  0            two           two    NUM   CD  nummod   \n",
       "3                  0  organizations  organization   NOUN  NNS   nsubj   \n",
       "4                  0           have          have    AUX  VBP     aux   \n",
       "...              ...            ...           ...    ...  ...     ...   \n",
       "13209400       23310           spot          spot   NOUN   NN    pobj   \n",
       "13209401       23310            for           for    ADP   IN    prep   \n",
       "13209402       23310         Howard        Howard  PROPN  NNP    pobj   \n",
       "13209403       23310              .             .  PUNCT    .   punct   \n",
       "13209404       23310                               SPACE  _SP   punct   \n",
       "\n",
       "          Polarity Label  \n",
       "0         0.000000     W  \n",
       "1         0.000000     W  \n",
       "2         0.000000     W  \n",
       "3        -0.193345     W  \n",
       "4        -0.046438     W  \n",
       "...            ...   ...  \n",
       "13209400 -0.001930     M  \n",
       "13209401  0.000000     M  \n",
       "13209402 -0.001477     M  \n",
       "13209403  0.000000     M  \n",
       "13209404  0.000000     M  \n",
       "\n",
       "[13209405 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "5ce0bbaaba556c243eee45087b7684ce43fda2aa9a5b0798832d1be21bf73af7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}