{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor of DataPrepper\n"
     ]
    }
   ],
   "source": [
    "# LOAD CLASS AND DATASET \n",
    "# dataset: https://www.kaggle.com/rmisra/news-category-dataset\n",
    "# start:    each doc in corpus contains an article link, category and other (irrelevant) key/value pairs\n",
    "# end goal: each doc in corpus contains a sentence with POS tagging and gender polarity, and label vector with actual gender\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from classes.data_prepper import DataPrepper\n",
    "\n",
    "p = DataPrepper()\n",
    "\n",
    "data = p.load_json('datasets/1_newsDataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER CATEGORIES\n",
    "\n",
    "men_categories = ['SPORTS', 'MONEY', 'BUSINESS']\n",
    "women_categories = ['WOMEN', 'STYLE & BEAUTY']\n",
    "\n",
    "data['articles'] = p.filter_articles(men_categories+women_categories, data['articles'])\n",
    "\n",
    "p.write_json('datasets/2_filtered_news_data.json', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPE LINKS\n",
    "\n",
    "scraped_data = {}\n",
    "scraped_data['articles'] = []\n",
    "textlessUrls = []\n",
    "\n",
    "for article in data['articles']:\n",
    "    text = p.scrape_url(article['link'], textlessUrls)\n",
    "    gender = 'M' if article['category'] in men_categories else 'W'\n",
    "    if text != \"\":\n",
    "        scraped_data['articles'].append({'gender': gender, 'text': text})\n",
    "\n",
    "p.write_json('datasets/3_text_and_gender.json', scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE NLP FROM SPACY\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23311\n",
      "17483\n",
      "At least two organizations have decided to drop Morgan Freeman after eight women accused him of inappropriate behavior and sexual harassment. Women who previously worked with the Oscar-winning actor told CNN that he repeatedly made comments about their bodies or their clothing and frequently engaged in inappropriate touching. In response to the allegations, Visa announced it had suspended him from its marketing campaign.  We are aware of the allegations that have been made against Mr. Freeman. At this point, Visa will be suspending our marketing in which the actor is featured,  Visa said in a statement. TransLink, Vancouver’s public transit system, also decided to stop using Freeman’s voice as part of an ad campaign to promote its Visa credit card and mobile payments on bus and Skytrain operations.  In light of information we’ve learned ... of allegations regarding actor Morgan Freeman, TransLink has decided to pause his voice announcements as part of a Visa ad campaign on our transit system,  the transit system said a statement.  We will be reaching out to Visa to discuss further.  A few hours after the report was released, Freeman, 80, issued an apology:  Anyone who knows me or has worked with me knows I am not someone who would intentionally offend or knowingly make anyone feel uneasy, I apologize to anyone who felt uncomfortable or disrespected — that was never my intent.  A production assistant working on the 2015 film  Going in Style  said Morgan made numerous comments about her body, asked her several times if she was wearing underwear and tried to lift her skirt. Another worker on the set said women wore loose-fitting clothing in an effort to avoid Freeman’s attention. Entertainment Tonight released footage on Thursday evening of two on-air interviews with Freeman that also revealed his attitude toward women. During an interview for the 2016 film  London Has Fallen,  Freeman asked a young female reporter,  My goodness, are you married? Fool around with other guys? I’m just asking.  In 2015, he told author Janet Mock:  You got a dress halfway between your knee and your hips, and you sit down right across from me and you cross your legs.  Mock, who was a special correspondent for the interview, said Freeman’s treatment of her was an  exhibition of the casual nature at which men in positions of power believe that everything belongs to them, including women’s bodies.  Freeman’s union, SAG-AFTRA, is considering what to do about Freeman’s Life Achievement Award. The award is given to actors who represent the  finest ideals of the acting profession,  CNN reported.  These are compelling and devastating allegations which are absolutely contrary to all the steps that we are taking to ensure a safe work environment,  the union said in a statement.  Any accused person has the right to due process, but it is our starting point to believe the courageous voices who come forward to report incidents of harassment ... we are reviewing what corrective actions may be warranted at this time.  \n"
     ]
    }
   ],
   "source": [
    "scraped_data = p.load_json('datasets/3_text_and_gender.json')\n",
    "print(len(scraped_data['articles']))\n",
    "\n",
    "split = round(len(scraped_data['articles'])*0.75)\n",
    "scraped_data['articles'] = scraped_data['articles'][:split]\n",
    "print(len(scraped_data['articles']))\n",
    "print(scraped_data['articles'][0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE WEIGHTS FOR EACH TERM\n",
    "# using tf-idf weighting from 'An Introduction to Information Retrieval (2009 Online Edition)'\n",
    "# written by Christopher D. Manning, Prabhakar Raghavan & Hinrich Schütze\n",
    "ignore_terms = ['.', ',', '...', ' ', '\\u2019', '  ', '(', ')', '?', '\\u00a3', '/', '\"', ':', ';', '-', '--', '\\u2015', \"'\", '!', '$', '#', '\\u2014', '   ', '[',']']\n",
    "ignore_ents = ['TIME', 'DATE', 'GPE', 'CARDINAL', 'PERSON', 'MONEY', 'PERCENT']\n",
    "\n",
    "m_weights, w_weights = p.get_weight s(scraped_data['articles'], nlp, ignore_terms, ignore_ents)\n",
    "\n",
    "p.write_json('datasets/4_word_weight_m.json', m_weights)\n",
    "p.write_json('datasets/4_word_weight_w.json', w_weights)\n",
    "\n",
    "p.write_json('datasets/4_word_weight_m_ordered.json', p.order_dict(m_weights, 'desc'))\n",
    "p.write_json('datasets/4_word_weight_w_ordered.json', p.order_dict(w_weights, 'desc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE WEIGHTS\n",
    "\n",
    "p.normalize_dict(m_weights)\n",
    "p.normalize_dict(w_weights)\n",
    "\n",
    "p.write_json('datasets/5_word_weight_m_norm.json', m_weights)\n",
    "p.write_json('datasets/5_word_weight_w_norm.json', w_weights)\n",
    "\n",
    "p.write_json('datasets/5_word_weight_m_norm_ordered.json', p.order_dict(m_weights, 'desc'))\n",
    "p.write_json('datasets/5_word_weight_w_norm_ordered.json', p.order_dict(w_weights, 'desc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE POLARITY FOR EACH TERM\n",
    "# -1 (man) to 1 (woman)\n",
    "\n",
    "polarity_dict = p.get_polarity(w_weights, m_weights)\n",
    "p.write_json('datasets/6_word_polarity.json', polarity_dict)\n",
    "p.write_json('datasets/6_word_polarity_ordered.json', p.order_dict(polarity_dict, 'desc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRAP ALL INTO FINAL DATASET\n",
    "# split all texts into sentences into words, each assigned sentence #, word, lemma, pos, dep and polarity\n",
    "# runtime: ~31 min\n",
    "\n",
    "data = p.load_json('datasets/3_text_and_gender.json')\n",
    "polarity_dict = p.load_json('datasets/6_word_polarity.json')\n",
    "\n",
    "corpus =    {\n",
    "                'Sentence #': [], \n",
    "                'Word': [],\n",
    "                'Lemma': [],\n",
    "                'Tag': [],\n",
    "                'POS': [],\n",
    "                'Dep': [],\n",
    "                'Polarity': [],\n",
    "                'Gender': []\n",
    "            }\n",
    "\n",
    "sentenceCount = 1\n",
    "\n",
    "ignore_terms = ['.', ',', '...', ' ', '\\u2019', '  ', '(', ')', '?', '\\u00a3', '/', '\"', ':', ';', '-', '--', '\\u2015', \"'\", '!', '$', '#', '\\u2014', '   ', '[',']']\n",
    "ignore_ents = ['TIME', 'DATE', 'GPE', 'CARDINAL', 'PERSON', 'MONEY', 'PERCENT']\n",
    "\n",
    "for article in data['articles']:\n",
    "    doc = nlp(article['text'])\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if not token.is_stop and token.lemma_ not in ignore_terms and token.ent_type_ not in ignore_ents:\n",
    "                corpus['Sentence #'].append(sentenceCount)\n",
    "                corpus['Word'].append(token.text)\n",
    "                corpus['Lemma'].append(token.lemma_)\n",
    "                corpus['Tag'].append(token.tag_)\n",
    "                corpus['POS'].append(token.pos_)\n",
    "                corpus['Dep'].append(token.dep_)\n",
    "                corpus['Polarity'].append(polarity_dict[token.lemma_] if token.lemma_ in polarity_dict else 0)\n",
    "                corpus['Gender'].append(article['gender'])\n",
    "        sentenceCount += 1\n",
    "\n",
    "p.write_json('datasets/7_dataset_w_tags.json', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-5-037853430cd5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-037853430cd5>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    df = pd.read_json('C:\\Users\\hanse\\OneDrive - Aarhus Universitet\\IKT-studie\\BachelorProjekt\\ML-Iterationer\\Sentiment\\dataset_backups\\11.10.2021/7_dataset_SM.json')\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATASET WITH PANDA \n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_json('datasets/7_dataset_SM.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SIMPLE DATASET\n",
    "# each row contains sentence and gender\n",
    "\n",
    "data = p.load_json('datasets/3_text_and_gender_SM.json')\n",
    "polarity_dict = p.load_json('datasets/6_word_polarity.json')\n",
    "\n",
    "corpus =    {\n",
    "                'Text': [],\n",
    "                'Gender': []\n",
    "            }\n",
    "\n",
    "ignore_terms = ['.', ',', '...', ' ', '\\u2019', '  ', '(', ')', '?', '\\u00a3', '/', '\"', ':', ';', '-', '--', '\\u2015', \"'\", '!', '$', '#', '\\u2014', '   ', '[',']']\n",
    "ignore_ents = ['TIME', 'DATE', 'GPE', 'CARDINAL', 'PERSON', 'MONEY', 'PERCENT']\n",
    "\n",
    "for article in data['articles']:\n",
    "    doc = nlp(article['text'])\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    for sent in doc.sents:\n",
    "        text = p.preprocess_text(sent.text)\n",
    "        if text != \" \":\n",
    "            corpus['Text'].append(text)\n",
    "            corpus['Gender'].append(article['gender'])\n",
    "\n",
    "p.write_json('datasets/8_dataset_simple_SM.json', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing at my home from of yes'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '.. . testing , \" at my home from of yes'\n",
    "\n",
    "p.preprocess_text(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00922dfc658c9c6d5a8441e23ac7ecd5da2a81953be115dd7d5d471af81b74e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
