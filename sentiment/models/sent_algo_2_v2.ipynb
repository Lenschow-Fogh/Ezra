{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment algorithm 1. Sequence of lemmas as single feature input and binary classification of sentence as output\n",
    "\n",
    "# Model is saved in saved_models/model_name/model_variant.h5\n",
    "# Run history is saved in logged_models/model_name sorted by model_variants and run-datetime\n",
    "# Runs can be viewed using tensorboard: tensorboard --logdir=PATH --port=6006\n",
    "# Example given: tensorboard --logdir=C:\\BAC\\Ezra\\sentiment\\models\\logged_models\\sent_algo_1 --port=6006\n",
    "model_name = 'sent_algo_2'\n",
    "model_variant = 'w_mask'\n",
    "\n",
    "training_size = 3000000\n",
    "test_size = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP IMPORTS\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import models\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "pd.set_option('display.max_columns', 10, 'display.width', 10, 'display.max_colwidth', 20, 'display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASET\n",
    "df = pd.read_json('../datasets/sentiment_corpus.json')\n",
    "print(\"Corpus sample size is:\", len(df))\n",
    "\n",
    "print(training_size, \"samples are taken from the head for training\")\n",
    "print(test_size, \"samples are taken from the tail for test\")\n",
    "\n",
    "# We take from the head for training data and tail for test data\n",
    "# This is done since the last 25% of the corpus is not fitted on the polarity dict, thereby preventing overfitting\n",
    "train_data = df.head(training_size)\n",
    "test_data = df.tail(test_size)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP-BY SENTENCE NUMBER \n",
    "train_data = train_data.groupby(['Sentence #'],as_index=False)['Word', 'Lemma', 'POS', 'Polarity', 'Gender'].agg(lambda x: list(x))\n",
    "test_data = test_data.groupby(['Sentence #'],as_index=False)['Word', 'Lemma', 'POS', 'Polarity', 'Gender'].agg(lambda x: list(x))\n",
    "\n",
    "def gender_seq_to_single(seqs):\n",
    "    genders = []\n",
    "    for seq in seqs:\n",
    "        genders.append(seq[0])\n",
    "    return genders\n",
    "\n",
    "train_data['Gender'] = gender_seq_to_single(train_data['Gender'])\n",
    "test_data['Gender'] = gender_seq_to_single(test_data['Gender'])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE TRAINING AND TEST DATA\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQUAL GENDER SAMPLES TO PREVENT BIAS\n",
    "def equal_genders(data_):\n",
    "    M, F = data_[\"Gender\"].value_counts()\n",
    "    if M>F:\n",
    "        diff = M-F\n",
    "        return data_.drop(data_.loc[data_['Gender'] == 'M'].index[:diff], axis=0)\n",
    "    elif F>M:\n",
    "        diff = F-M\n",
    "        return data_.drop(data_.loc[data_['Gender'] == 'F'].index[:diff], axis=0)\n",
    "\n",
    "train_data = equal_genders(train_data)\n",
    "test_data = equal_genders(test_data)\n",
    "\n",
    "train_data[\"Gender\"].value_counts().plot(kind=\"bar\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FUNCTION FOR PLOTTING SENTENCE LENGTHS\n",
    "def plot_sentence_lengths(data_):\n",
    "    sentence_plot = data_[\"Word\"].values\n",
    "    sentence_plot_sorted = list(sorted(sentence_plot, key=len))\n",
    "    c = Counter(map(len, sentence_plot_sorted))\n",
    "\n",
    "    total_sentences = 0\n",
    "    total_words = 0\n",
    "    for i in c:\n",
    "        total_sentences = total_sentences + c[i]\n",
    "        total_words = total_words + c[i]*i\n",
    "\n",
    "    sentences_80_pct = total_sentences / 100 * 90\n",
    "    words_80_pct = total_words / 100 * 90\n",
    "\n",
    "    boundary_sen = 0\n",
    "    counter_sen = 0\n",
    "\n",
    "    for i in c:\n",
    "        if(counter_sen + c[i] < int(sentences_80_pct)):\n",
    "            counter_sen = counter_sen + c[i]\n",
    "            boundary_sen = i\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    boundary_word = 0\n",
    "    counter_word = 0\n",
    "\n",
    "    for i in c:\n",
    "        if(counter_word + c[i] * i < int(words_80_pct)):\n",
    "            counter_word = counter_word + c[i] * i\n",
    "            boundary_word = i\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    my_cmap = plt.get_cmap(\"viridis\")\n",
    "    rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=[10,6])\n",
    "    bars = plt.bar(list(c.keys()), list(c.values()), color=my_cmap(rescale(list(c.values()))), width=0.8, alpha=0.7, align='center')\n",
    "\n",
    "    # for r in bars.get_children():\n",
    "    #     if(r.get_x() > boundary_sen):\n",
    "    #         r.set_alpha(0.2)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.ylim([0, max(list(c.values()))+10])\n",
    "    ax2 = plt.gca()\n",
    "\n",
    "    ymin, ymax = ax2.get_ylim()\n",
    "    plt.vlines(boundary_sen, ymin=ymin, ymax=ymax, colors='r', label='80% of sentences')\n",
    "    # plt.vlines(boundary_word, ymin=ymin, ymax=ymax, colors='black', label=\"80% of words\")\n",
    "\n",
    "    plt.ylabel('Frequency of sentence', fontdict={'fontsize':13, 'fontweight': 'bold'})\n",
    "    plt.xlabel('# words in sentence', fontdict={'fontsize':13, 'fontweight': 'bold'})\n",
    "    plt.title(\"Distribution of sentence lengths\", fontdict={'fontsize':14, 'fontweight': 'bold'})\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return boundary_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE SENTENCE LENGTHS AND DECISION BOUNDARY\n",
    "decision_boundary = plot_sentence_lengths(train_data)\n",
    "print(\"Decision boundary / 80 pct of sentence lengths is:\", decision_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT TARGET (GENDER)\n",
    "classes = [-1.0, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "n_unique_classes = len(classes) + 1 # +1 for padding\n",
    "\n",
    "pol_to_enc = {\n",
    "    -1.0: 1,\n",
    "    -0.9: 2,\n",
    "    -0.8: 3,\n",
    "    -0.7: 4,\n",
    "    -0.6: 5,\n",
    "    -0.5: 6,\n",
    "    -0.4: 7,\n",
    "    -0.3: 8,\n",
    "    -0.2: 9,\n",
    "    -0.1: 10,\n",
    "    0.0: 11,\n",
    "    0.1: 12,\n",
    "    0.2: 13,\n",
    "    0.3: 14,\n",
    "    0.4: 15,\n",
    "    0.5: 16,\n",
    "    0.6: 17,\n",
    "    0.7: 18,\n",
    "    0.8: 19,\n",
    "    0.9: 20,\n",
    "    1.0: 21\n",
    "}\n",
    "\n",
    "def round_list(list):\n",
    "    rounded_pols = []\n",
    "    for seq in list:\n",
    "        rounded_pols.append([round(pol,1) for pol in seq])\n",
    "    return rounded_pols\n",
    "\n",
    "def encode_list(list):\n",
    "    # le = LabelEncoder()\n",
    "    # le.fit_transform(classes)\n",
    "\n",
    "    # encoded_pols = []\n",
    "    # for seq in list:\n",
    "    #     encoded_pols.append(le.transform(seq))\n",
    "    # return encoded_pols\n",
    "\n",
    "    encoded_pols = []\n",
    "    for seq in list:\n",
    "        encoded_pols.append([pol_to_enc[pol] for pol in seq])\n",
    "    return encoded_pols\n",
    "\n",
    "def one_hot_list(list):\n",
    "    one_hot_pols = []\n",
    "    for seq in list:\n",
    "        one_hot_pols.append([to_categorical(pol, n_unique_classes) for pol in seq])\n",
    "    return one_hot_pols\n",
    "\n",
    "train_pols_rounded = round_list(train_data['Polarity'])\n",
    "train_pols_encoded = encode_list(train_pols_rounded)\n",
    "y_train = one_hot_list(train_pols_encoded)\n",
    "\n",
    "test_pols_rounded = round_list(test_data['Polarity'])\n",
    "test_pols_encoded = encode_list(test_pols_rounded)\n",
    "y_test = one_hot_list(test_pols_encoded)\n",
    "\n",
    "\n",
    "print(\"Unique polarities:\", [classes])\n",
    "print(\"Unique polarities:\", encode_list([classes]))\n",
    "\n",
    "print(\"\\nTraining data example polarity sequence:\", train_data['Polarity'][:1].tolist())\n",
    "print(\"Training data example polarity sequence rounded:\", train_pols_rounded[0])\n",
    "print(\"Training data example polarity sequence encoded:\", train_pols_encoded[0])\n",
    "print(\"Training data example polarity sequence one-hot:\", y_train[0])\n",
    "\n",
    "print(\"\\nTest data example polarity sequence:\", test_data['Polarity'][:1].tolist())\n",
    "print(\"Test data example polarity sequence rounded:\", test_pols_rounded[0])\n",
    "print(\"Test data example polarity sequence encoded:\", test_pols_encoded[0])\n",
    "print(\"Test data example polarity sequence one-hot:\", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE FEATURES TO INTEGERS, EQUAL LENGTHS AND PAD\n",
    "# Inspired by: https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n",
    "def encode_feature(train_data_, test_data_):\n",
    "    tokenizer = Tokenizer()\n",
    "    # ONLY FIT ON TRAIN DATA\n",
    "    tokenizer.fit_on_texts(train_data_)\n",
    "    return tokenizer.texts_to_sequences(train_data_), tokenizer.texts_to_sequences(test_data_), len(tokenizer.word_index)\n",
    "\n",
    "train_data['Lemma_enc'], test_data['Lemma_enc'], vocab_size = encode_feature(train_data['Lemma'], test_data['Lemma'])\n",
    "\n",
    "\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "max_len = decision_boundary\n",
    "\n",
    "X_train = pad_sequences(train_data['Lemma_enc'], dtype='float32', padding=padding_type, truncating=trunc_type, maxlen=max_len)\n",
    "X_test = pad_sequences(test_data['Lemma_enc'], dtype='float32', padding=padding_type, truncating=trunc_type, maxlen=max_len)\n",
    "\n",
    "y_train = pad_sequences(y_train, dtype='float32', padding=padding_type, truncating=trunc_type, maxlen=max_len)\n",
    "y_test = pad_sequences(y_test, dtype='float32', padding=padding_type, truncating=trunc_type, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING KERAS CALLBACKS\n",
    "\n",
    "# Borrowed from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"./logged_models/\" + model_name + '/' + model_variant)\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_log_dir = get_run_logdir()\n",
    "file_writer = tf.summary.create_file_writer(run_log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_log_dir)\n",
    "\n",
    "my_callbacks = [earlystopping, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING AND PLOTTING MODEL\n",
    "embedding_dim = 128\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(vocab_size+1, embedding_dim, input_length=max_len, mask_zero=True),\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)),\n",
    "    layers.TimeDistributed(layers.Dense(n_unique_classes, activation=\"softmax\"))#PRØV AT ØGE UNIQUE CLASSES MED 1 FOR PADDING\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # cross entropy loss chapter 4 HOML - categorial crossentropy because to_categorial \n",
    "\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING MODEL\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, callbacks=my_callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HISTORY OF FITTING\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs=range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', 'Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', 'Validation Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "print(\"red is training, blue is validation\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING MODEL\n",
    "model.save('saved_models/' + model_name + '/' + model_variant + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT TEST DATA\n",
    "y_pred = model.predict(X_test)\n",
    "cm_pred = y_pred.argmax(axis=-1).flatten()\n",
    "cm_true = y_test.argmax(axis=-1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for seq in test_data['Polarity'].to_numpy():\n",
    "    count += len(seq)\n",
    "count\n",
    "print(\"test_data polarities length\", count)\n",
    "print(\"cm_pred shape\", cm_pred.shape)\n",
    "print(\"cm_true shape\", cm_true.shape)\n",
    "print(\"MEANING\", cm_pred.shape[0]-count, \"polarities are paddings\")\n",
    "print(cm_pred[:50])\n",
    "print(cm_true[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING CONFUSION MATRIX\n",
    "cm = confusion_matrix(cm_true, cm_pred, normalize='pred')\n",
    "\n",
    "fig = plt.figure( figsize=[18.5,10.5])\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "ax.set_xlabel('Predicted gender', fontsize = 15, labelpad=15.0)\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.set_ylabel('True gender', fontsize = 15, labelpad=15.0)\n",
    "ax.set_title('Multi sentiment classification',fontweight=\"bold\", size=20, pad=100.0)\n",
    "\n",
    "enc_to_pol = {\n",
    "  0: \"PAD\",\n",
    "  1 : -1.0,\n",
    "  2 : -0.9,\n",
    "  3 : -0.8,\n",
    "  4 : -0.7,\n",
    "  5 : -0.6,\n",
    "  6 : -0.5,\n",
    "  7 : -0.4,\n",
    "  8 : -0.3,\n",
    "  9 : -0.2,\n",
    "  10 : -0.1,\n",
    "  11 : 0.0,\n",
    "  12 : 0.1,\n",
    "  13 : 0.2,\n",
    "  14 : 0.3,\n",
    "  15 : 0.4,\n",
    "  16 : 0.5,\n",
    "  17 : 0.6,\n",
    "  18 : 0.7,\n",
    "  19 : 0.8,\n",
    "  20 : 0.9,\n",
    "  21 : 1.0,\n",
    "}\n",
    "\n",
    "cm_axis_vals = []\n",
    "\n",
    "for x in np.unique(np.array(np.concatenate((cm_true,cm_pred)))):\n",
    "    cm_axis_vals.append(enc_to_pol[x])\n",
    "\n",
    "fig.colorbar(cax)\n",
    "plt.xticks(range(len(cm_axis_vals)), cm_axis_vals, rotation=90)\n",
    "plt.yticks(range(len(cm_axis_vals)), cm_axis_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINTING METRICS\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(cm_true, cm_pred, output_dict=True)\n",
    "df_perf = pd.DataFrame.from_dict(report).transpose()\n",
    "df_perf_2 = df_perf[:len(cm_axis_vals)]\n",
    "df_perf_2.insert(loc=0, column='Polarity', value=cm_axis_vals)\n",
    "df_perf_2.precision = df_perf_2.precision.round(2)\n",
    "df_perf_2.recall = df_perf_2.recall.round(2)\n",
    "df_perf_2['f1-score'] = df_perf_2['f1-score'].round(2)\n",
    "df_perf_2.support = df_perf_2.support.round()\n",
    "df_perf_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "df_perf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE XAI FUNCTION\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from classes.data_prepper import DataPrepper\n",
    "\n",
    "# Borrowed from: https://www.geeksforgeeks.org/python-program-to-find-n-largest-elements-from-a-list/\n",
    "# Function returns N largest elements\n",
    "def Nmaxelements(list, N):\n",
    "    return list[:N]\n",
    "\n",
    "def find_complete_sentence(sentence_number, sentences):\n",
    "    index = sentences.index[sentences['Sentence #'] == sentence_number].tolist()[0]\n",
    "    return sentences['Text'][index]\n",
    "\n",
    "# Equation 8\n",
    "def p_s(polarities):\n",
    "    count = sum(map(lambda x: x > 0.0 or x < 0.0, polarities))\n",
    "    return round(sum(polarities) / count,1) if count > 0 else 0.0\n",
    "    \n",
    "\n",
    "def XAI(predictions, input_data, N_greatest_polarities):\n",
    "    p = DataPrepper()\n",
    "    complete_sentences = pd.read_json('../datasets/7_sentences.json')\n",
    "\n",
    "    for pred_seq, row in zip(predictions, input_data.iterrows()):\n",
    "        data = row[1]\n",
    "\n",
    "        pred_seq = [enc_to_pol[v] for v in pred_seq]\n",
    "        sentiment = p_s(pred_seq)\n",
    "\n",
    "        if (sentiment > 0.1 or sentiment < -0.1):\n",
    "            print(\"\\n---------------------------------------------------------------------------------------\")\n",
    "            print(\"The sentence:\", '\"'+find_complete_sentence(data['Sentence #'], complete_sentences)+'\".\\n')\n",
    "            print(\"Was predicted to be\", 'masculine' if sentiment < 0.0 else 'feminine', \"(\"+str(sentiment)+\").\\n\")\n",
    "\n",
    "            print(\"Most\", 'masculine' if sentiment < 0 else 'feminine', \"words in sentence are:\\n\")\n",
    "            greatest_pols = []\n",
    "\n",
    "            if (sentiment < 0):\n",
    "                greatest_pols = Nmaxelements(sorted(pred_seq), N_greatest_polarities)\n",
    "            else:\n",
    "                greatest_pols = Nmaxelements(sorted(pred_seq, reverse=True), N_greatest_polarities)\n",
    "\n",
    "            index = test_data.index[test_data['Sentence #'] == data[\"Sentence #\"]].tolist()[0]\n",
    "            for pol in greatest_pols:\n",
    "                i = pred_seq.index(pol)\n",
    "                word = 'ERROR: A padding was predicted' if i+1 > len(data[\"Word\"]) else \"'\"+data[\"Word\"][i]+\"'\"\n",
    "                print(word, \"with a polarity of\", round(pol,2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE XAI ON PREDICTIONS\n",
    "XAI(y_pred.argmax(axis=-1)[:500], test_data, 2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ce0bbaaba556c243eee45087b7684ce43fda2aa9a5b0798832d1be21bf73af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
