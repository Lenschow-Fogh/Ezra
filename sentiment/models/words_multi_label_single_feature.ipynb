{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_to_rep = {\n",
    "  -1.0: 0,\n",
    "  -0.9: 1,\n",
    "  -0.8: 2,\n",
    "  -0.7: 3,\n",
    "  -0.6: 4,\n",
    "  -0.5: 5,\n",
    "  -0.4: 6,\n",
    "  -0.3: 7,\n",
    "  -0.2: 8,\n",
    "  -0.1: 9,\n",
    "  -0.0: 10,\n",
    "  0.0: 10,\n",
    "  0.1: 11,\n",
    "  0.2: 12,\n",
    "  0.3: 13,\n",
    "  0.4: 14,\n",
    "  0.5: 15,\n",
    "  0.6: 16,\n",
    "  0.7: 17,\n",
    "  0.8: 18,\n",
    "  0.9: 19,\n",
    "  1.0: 20,\n",
    "}\n",
    "\n",
    "rep_to_pol = {\n",
    "  0 : -1.0,\n",
    "  1 : -0.9,\n",
    "  2 : -0.8,\n",
    "  3 : -0.7,\n",
    "  4 : -0.6,\n",
    "  5 : -0.5,\n",
    "  6 : -0.4,\n",
    "  7 : -0.3,\n",
    "  8 : -0.2,\n",
    "  9 : -0.1,\n",
    "  10 : 0.0,\n",
    "  11 : 0.1,\n",
    "  12 : 0.2,\n",
    "  13 : 0.3,\n",
    "  14 : 0.4,\n",
    "  15 : 0.5,\n",
    "  16 : 0.6,\n",
    "  17 : 0.7,\n",
    "  18 : 0.8,\n",
    "  19 : 0.9,\n",
    "  20 : 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\AppData\\Local\\Temp/ipykernel_21120/1689357596.py:34: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df = df.groupby(['Sentence #'],as_index=False)['Word', 'Lemma', 'Tag', 'POS', 'Dep', 'Polarity', 'Sentiment', 'Polarity_rounded', 'Word_index'].agg(lambda x: list(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Tag</th>\n",
       "      <th>POS</th>\n",
       "      <th>Dep</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Polarity_rounded</th>\n",
       "      <th>Word_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[In, response, to, the, allegations, ,, Visa, ...</td>\n",
       "      <td>[in, response, to, the, allegation, ,, Visa, a...</td>\n",
       "      <td>[IN, NN, IN, DT, NNS, ,, NNP, VBD, PRP, VBD, V...</td>\n",
       "      <td>[ADP, NOUN, ADP, DET, NOUN, PUNCT, PROPN, VERB...</td>\n",
       "      <td>[PREP, POBJ, PREP, DET, POBJ, PUNCT, NSUBJ, RO...</td>\n",
       "      <td>[-0.006838350176682001, -0.056195008783595006,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 9, 10, 10, 10, 10, 10, 9, 10, 9, 9, 10, 1...</td>\n",
       "      <td>[35011, 109287, 117748, 117168, 71501, 183, 67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[ , We, are, aware, of, the, allegations, that...</td>\n",
       "      <td>[ , we, be, aware, of, the, allegation, that, ...</td>\n",
       "      <td>[_SP, PRP, VBP, JJ, IN, DT, NNS, WDT, VBP, VBN...</td>\n",
       "      <td>[SPACE, PRON, AUX, ADJ, ADP, DET, NOUN, DET, A...</td>\n",
       "      <td>[PUNCT, NSUBJ, ROOT, ACOMP, PREP, DET, POBJ, N...</td>\n",
       "      <td>[0.0, -0.0, 0.0, -0.045806013513103004, 0.0, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 8, 10,...</td>\n",
       "      <td>[30, 68162, 72459, 73247, 101633, 117168, 7150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[At, this, point, ,, Visa, will, be, suspendin...</td>\n",
       "      <td>[at, this, point, ,, Visa, will, be, suspend, ...</td>\n",
       "      <td>[IN, DT, NN, ,, NNP, MD, VB, VBG, PRP$, NN, IN...</td>\n",
       "      <td>[ADP, DET, NOUN, PUNCT, PROPN, AUX, AUX, VERB,...</td>\n",
       "      <td>[PREP, DET, POBJ, PUNCT, NSUBJ, AUX, AUX, CCOM...</td>\n",
       "      <td>[0.0, 0.0, -0.24290105347972302, 0.0, -0.01495...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 10, 8, 10, 10, 10, 10, 9, 10, 8, 10, 10, ...</td>\n",
       "      <td>[11766, 117360, 105038, 183, 67118, 122186, 73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[TransLink, ,, Vancouver, ’s, public, transit,...</td>\n",
       "      <td>[TransLink, ,, Vancouver, ’s, public, transit,...</td>\n",
       "      <td>[NNP, ,, NNP, POS, JJ, NN, NN, ,, RB, VBD, TO,...</td>\n",
       "      <td>[PROPN, PUNCT, PROPN, PART, ADJ, NOUN, NOUN, P...</td>\n",
       "      <td>[NSUBJ, PUNCT, POSS, CASE, AMOD, COMPOUND, APP...</td>\n",
       "      <td>[0.000842479945457, 0.0, -0.001383951859845000...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 10, 10, 10, 8, 10, 8, 10, 10, 9, 10, 9, 8...</td>\n",
       "      <td>[64715, 183, 66556, 123622, 106692, 118299, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>[ ]</td>\n",
       "      <td>[_SP]</td>\n",
       "      <td>[SPACE]</td>\n",
       "      <td>[ROOT]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574676</th>\n",
       "      <td>668171</td>\n",
       "      <td>[We, ca, n't, just, have, guys, or, anybody, o...</td>\n",
       "      <td>[we, ca, n't, just, have, guy, or, anybody, ou...</td>\n",
       "      <td>[PRP, MD, RB, RB, VB, NNS, CC, NN, RB, RB, RB,...</td>\n",
       "      <td>[PRON, AUX, PART, ADV, VERB, NOUN, CCONJ, PRON...</td>\n",
       "      <td>[NSUBJ, AUX, NEG, ADVMOD, CCOMP, DOBJ, CC, CON...</td>\n",
       "      <td>[-0.0, 0.0, 0.0, 0.0, -0.07161671551935, -0.05...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[10, 10, 10, 10, 9, 9, 10, 10, 10, 10, 10, 7, ...</td>\n",
       "      <td>[68162, 76345, 100342, 95531, 91200, 90695, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574677</th>\n",
       "      <td>668172</td>\n",
       "      <td>[ , Trade, rumors, about, the, reigning, Defen...</td>\n",
       "      <td>[ , Trade, rumor, about, the, reign, Defensive...</td>\n",
       "      <td>[_SP, NNP, NNS, IN, DT, VBG, NNP, NNP, IN, DT,...</td>\n",
       "      <td>[SPACE, PROPN, NOUN, ADP, DET, VERB, PROPN, PR...</td>\n",
       "      <td>[NUMMOD, COMPOUND, NSUBJ, PREP, DET, AMOD, COM...</td>\n",
       "      <td>[0.0, -0.031460805351582, 0.000135464916235000...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...</td>\n",
       "      <td>[30, 64649, 110281, 70459, 117168, 108505, 226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574678</th>\n",
       "      <td>668173</td>\n",
       "      <td>[Before, the, season, ,, Howard, was, said, to...</td>\n",
       "      <td>[before, the, season, ,, Howard, be, say, to, ...</td>\n",
       "      <td>[IN, DT, NN, ,, NNP, VBD, VBN, TO, VB, VBN, DT...</td>\n",
       "      <td>[ADP, DET, NOUN, PUNCT, PROPN, AUX, VERB, PART...</td>\n",
       "      <td>[PREP, DET, POBJ, PUNCT, NSUBJPASS, AUXPASS, R...</td>\n",
       "      <td>[0.0, 0.0, -0.148026069781541, 0.0, -0.0022731...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[10, 10, 9, 10, 10, 10, 5, 10, 9, 8, 10, 8, 10...</td>\n",
       "      <td>[13664, 117168, 111261, 183, 34012, 121583, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574679</th>\n",
       "      <td>668174</td>\n",
       "      <td>[Just, last, week, ,, he, added, the, new, -, ...</td>\n",
       "      <td>[just, last, week, ,, he, add, the, new, -, lo...</td>\n",
       "      <td>[RB, JJ, NN, ,, PRP, VBD, DT, JJ, HYPH, NN, NN...</td>\n",
       "      <td>[ADV, ADJ, NOUN, PUNCT, PRON, VERB, DET, ADJ, ...</td>\n",
       "      <td>[ADVMOD, AMOD, NPADVMOD, PUNCT, NSUBJ, ROOT, D...</td>\n",
       "      <td>[0.0, -0.013723819280762, -0.027286346296288, ...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 9, 10, 7, 10, 10, 9, 9, 1...</td>\n",
       "      <td>[37097, 96221, 121797, 183, 91245, 70864, 1171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574680</th>\n",
       "      <td>668175</td>\n",
       "      <td>[The, Knicks, and, Celtics, have, also, been, ...</td>\n",
       "      <td>[the, Knicks, and, Celtics, have, also, be, na...</td>\n",
       "      <td>[DT, NNPS, CC, NNPS, VBP, RB, VBN, VBN, IN, NN...</td>\n",
       "      <td>[DET, PROPN, CCONJ, PROPN, AUX, ADV, AUX, VERB...</td>\n",
       "      <td>[DET, NSUBJPASS, CC, CONJ, AUX, ADVMOD, AUXPAS...</td>\n",
       "      <td>[0.0, -0.054292103429926006, 0.000266154791326...</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "      <td>[10, 9, 10, 10, 9, 10, 10, 9, 10, 9, 10, 10, 9...</td>\n",
       "      <td>[63730, 38470, 71882, 18250, 91200, 71609, 740...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574679 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                                               Word  \\\n",
       "2                3  [In, response, to, the, allegations, ,, Visa, ...   \n",
       "3                4  [ , We, are, aware, of, the, allegations, that...   \n",
       "4                5  [At, this, point, ,, Visa, will, be, suspendin...   \n",
       "5                6  [TransLink, ,, Vancouver, ’s, public, transit,...   \n",
       "6                7                                                [ ]   \n",
       "...            ...                                                ...   \n",
       "574676      668171  [We, ca, n't, just, have, guys, or, anybody, o...   \n",
       "574677      668172  [ , Trade, rumors, about, the, reigning, Defen...   \n",
       "574678      668173  [Before, the, season, ,, Howard, was, said, to...   \n",
       "574679      668174  [Just, last, week, ,, he, added, the, new, -, ...   \n",
       "574680      668175  [The, Knicks, and, Celtics, have, also, been, ...   \n",
       "\n",
       "                                                    Lemma  \\\n",
       "2       [in, response, to, the, allegation, ,, Visa, a...   \n",
       "3       [ , we, be, aware, of, the, allegation, that, ...   \n",
       "4       [at, this, point, ,, Visa, will, be, suspend, ...   \n",
       "5       [TransLink, ,, Vancouver, ’s, public, transit,...   \n",
       "6                                                     [ ]   \n",
       "...                                                   ...   \n",
       "574676  [we, ca, n't, just, have, guy, or, anybody, ou...   \n",
       "574677  [ , Trade, rumor, about, the, reign, Defensive...   \n",
       "574678  [before, the, season, ,, Howard, be, say, to, ...   \n",
       "574679  [just, last, week, ,, he, add, the, new, -, lo...   \n",
       "574680  [the, Knicks, and, Celtics, have, also, be, na...   \n",
       "\n",
       "                                                      Tag  \\\n",
       "2       [IN, NN, IN, DT, NNS, ,, NNP, VBD, PRP, VBD, V...   \n",
       "3       [_SP, PRP, VBP, JJ, IN, DT, NNS, WDT, VBP, VBN...   \n",
       "4       [IN, DT, NN, ,, NNP, MD, VB, VBG, PRP$, NN, IN...   \n",
       "5       [NNP, ,, NNP, POS, JJ, NN, NN, ,, RB, VBD, TO,...   \n",
       "6                                                   [_SP]   \n",
       "...                                                   ...   \n",
       "574676  [PRP, MD, RB, RB, VB, NNS, CC, NN, RB, RB, RB,...   \n",
       "574677  [_SP, NNP, NNS, IN, DT, VBG, NNP, NNP, IN, DT,...   \n",
       "574678  [IN, DT, NN, ,, NNP, VBD, VBN, TO, VB, VBN, DT...   \n",
       "574679  [RB, JJ, NN, ,, PRP, VBD, DT, JJ, HYPH, NN, NN...   \n",
       "574680  [DT, NNPS, CC, NNPS, VBP, RB, VBN, VBN, IN, NN...   \n",
       "\n",
       "                                                      POS  \\\n",
       "2       [ADP, NOUN, ADP, DET, NOUN, PUNCT, PROPN, VERB...   \n",
       "3       [SPACE, PRON, AUX, ADJ, ADP, DET, NOUN, DET, A...   \n",
       "4       [ADP, DET, NOUN, PUNCT, PROPN, AUX, AUX, VERB,...   \n",
       "5       [PROPN, PUNCT, PROPN, PART, ADJ, NOUN, NOUN, P...   \n",
       "6                                                 [SPACE]   \n",
       "...                                                   ...   \n",
       "574676  [PRON, AUX, PART, ADV, VERB, NOUN, CCONJ, PRON...   \n",
       "574677  [SPACE, PROPN, NOUN, ADP, DET, VERB, PROPN, PR...   \n",
       "574678  [ADP, DET, NOUN, PUNCT, PROPN, AUX, VERB, PART...   \n",
       "574679  [ADV, ADJ, NOUN, PUNCT, PRON, VERB, DET, ADJ, ...   \n",
       "574680  [DET, PROPN, CCONJ, PROPN, AUX, ADV, AUX, VERB...   \n",
       "\n",
       "                                                      Dep  \\\n",
       "2       [PREP, POBJ, PREP, DET, POBJ, PUNCT, NSUBJ, RO...   \n",
       "3       [PUNCT, NSUBJ, ROOT, ACOMP, PREP, DET, POBJ, N...   \n",
       "4       [PREP, DET, POBJ, PUNCT, NSUBJ, AUX, AUX, CCOM...   \n",
       "5       [NSUBJ, PUNCT, POSS, CASE, AMOD, COMPOUND, APP...   \n",
       "6                                                  [ROOT]   \n",
       "...                                                   ...   \n",
       "574676  [NSUBJ, AUX, NEG, ADVMOD, CCOMP, DOBJ, CC, CON...   \n",
       "574677  [NUMMOD, COMPOUND, NSUBJ, PREP, DET, AMOD, COM...   \n",
       "574678  [PREP, DET, POBJ, PUNCT, NSUBJPASS, AUXPASS, R...   \n",
       "574679  [ADVMOD, AMOD, NPADVMOD, PUNCT, NSUBJ, ROOT, D...   \n",
       "574680  [DET, NSUBJPASS, CC, CONJ, AUX, ADVMOD, AUXPAS...   \n",
       "\n",
       "                                                 Polarity  \\\n",
       "2       [-0.006838350176682001, -0.056195008783595006,...   \n",
       "3       [0.0, -0.0, 0.0, -0.045806013513103004, 0.0, 0...   \n",
       "4       [0.0, 0.0, -0.24290105347972302, 0.0, -0.01495...   \n",
       "5       [0.000842479945457, 0.0, -0.001383951859845000...   \n",
       "6                                                   [0.0]   \n",
       "...                                                   ...   \n",
       "574676  [-0.0, 0.0, 0.0, 0.0, -0.07161671551935, -0.05...   \n",
       "574677  [0.0, -0.031460805351582, 0.000135464916235000...   \n",
       "574678  [0.0, 0.0, -0.148026069781541, 0.0, -0.0022731...   \n",
       "574679  [0.0, -0.013723819280762, -0.027286346296288, ...   \n",
       "574680  [0.0, -0.054292103429926006, 0.000266154791326...   \n",
       "\n",
       "                                                Sentiment  \\\n",
       "2       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6                                                     [1]   \n",
       "...                                                   ...   \n",
       "574676  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "574677  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "574678  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "574679  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "574680  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...   \n",
       "\n",
       "                                         Polarity_rounded  \\\n",
       "2       [10, 9, 10, 10, 10, 10, 10, 9, 10, 9, 9, 10, 1...   \n",
       "3       [10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 8, 10,...   \n",
       "4       [10, 10, 8, 10, 10, 10, 10, 9, 10, 8, 10, 10, ...   \n",
       "5       [10, 10, 10, 10, 8, 10, 8, 10, 10, 9, 10, 9, 8...   \n",
       "6                                                    [10]   \n",
       "...                                                   ...   \n",
       "574676  [10, 10, 10, 10, 9, 9, 10, 10, 10, 10, 10, 7, ...   \n",
       "574677  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...   \n",
       "574678  [10, 10, 9, 10, 10, 10, 5, 10, 9, 8, 10, 8, 10...   \n",
       "574679  [10, 10, 10, 10, 10, 9, 10, 7, 10, 10, 9, 9, 1...   \n",
       "574680  [10, 9, 10, 10, 9, 10, 10, 9, 10, 9, 10, 10, 9...   \n",
       "\n",
       "                                               Word_index  \n",
       "2       [35011, 109287, 117748, 117168, 71501, 183, 67...  \n",
       "3       [30, 68162, 72459, 73247, 101633, 117168, 7150...  \n",
       "4       [11766, 117360, 105038, 183, 67118, 122186, 73...  \n",
       "5       [64715, 183, 66556, 123622, 106692, 118299, 11...  \n",
       "6                                                    [30]  \n",
       "...                                                   ...  \n",
       "574676  [68162, 76345, 100342, 95531, 91200, 90695, 10...  \n",
       "574677  [30, 64649, 110281, 70459, 117168, 108505, 226...  \n",
       "574678  [13664, 117168, 111261, 183, 34012, 121583, 11...  \n",
       "574679  [37097, 96221, 121797, 183, 91245, 70864, 1171...  \n",
       "574680  [63730, 38470, 71882, 18250, 91200, 71609, 740...  \n",
       "\n",
       "[574679 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('../datasets/7_dataset_w_tags_and_stopwords.json')\n",
    "\n",
    "M, W = df[\"Gender\"].value_counts()\n",
    "if M>W:\n",
    "    diff = M-W\n",
    "    df = df.drop(df.loc[df['Gender'] == 'M'].index[:diff], axis=0)\n",
    "elif W>M:\n",
    "    diff = W-M\n",
    "    df = df.drop(df.loc[df['Gender'] == 'W'].index[:diff], axis=0)\n",
    "\n",
    "df[\"Gender\"].value_counts().plot(kind=\"bar\", figsize=(10,5))\n",
    "df['Sentiment'] = df.Gender.apply(lambda x: -1 if x == \"M\" else 1)\n",
    "df = df.drop('Gender', axis=1)\n",
    "df['Dep'] = df['Dep'].str.upper()\n",
    "\n",
    "df['Polarity_rounded'] = df['Polarity'].apply(lambda s: pol_to_rep[round(float(s), 1)])\n",
    "\n",
    "word_vocab = np.unique(df['Word']).tolist()\n",
    "word_vocab.insert(0, '<PAD>')\n",
    "\n",
    "polarity_range = []\n",
    "\n",
    "for i in np.arange(0.0, 2.1, 0.1):\n",
    "    polarity_range.append(int(round(i*10, 1)))\n",
    "\n",
    "i_to_word = {i:word for  i, word in enumerate(word_vocab)}\n",
    "word_to_i = {word:i for  i, word in enumerate(word_vocab)}\n",
    "\n",
    "df['Word_index'] = df['Word'].map(word_to_i)\n",
    "\n",
    "\n",
    "df = df.groupby(['Sentence #'],as_index=False)['Word', 'Lemma', 'Tag', 'POS', 'Dep', 'Polarity', 'Sentiment', 'Polarity_rounded', 'Word_index'].agg(lambda x: list(x))\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# df['Word'].apply(lambda s: s.insert(0,\"<SOS>\"))\n",
    "# df['Word'].apply(lambda s: s.insert(len(s),\"<EOS>\"))\n",
    "# df['Polarity_rounded'].apply(lambda s: s.insert(0,10))\n",
    "# df['Polarity_rounded'].apply(lambda s: s.insert(len(s),10))\n",
    "\n",
    "\n",
    "print(polarity_range)\n",
    "\n",
    "df[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 32.0 KiB for an array with shape (390, 21) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21120/759920752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpad_polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpad_polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_to_rep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpad_polarities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrain_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_polarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_polarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21120/759920752.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpad_polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpad_polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_to_rep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpad_polarities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtrain_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_polarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_polarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 32.0 KiB for an array with shape (390, 21) and data type float32"
     ]
    }
   ],
   "source": [
    "tokens = df['Word_index'].tolist()\n",
    "polarities = df['Polarity_rounded'].tolist()\n",
    "\n",
    "max_length = max([len(s) for s in tokens])\n",
    "\n",
    "pad_tokens = pad_sequences(tokens, maxlen=max_length, dtype='int32', padding='post')\n",
    "pad_polarities = pad_sequences(polarities, maxlen=max_length, dtype='int32', padding='post', value=10)\n",
    "\n",
    "pad_polarities = [to_categorical(i, num_classes=len(pol_to_rep)) for i in pad_polarities]\n",
    "    \n",
    "train_tokens, test_tokens, train_polarities, test_polarities = train_test_split(pad_tokens, pad_polarities, test_size=0.4, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "\n",
    "# Borrowed from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 10, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "model_name = 'words_multi_label_single_feature'\n",
    "model_variant = 'base_w_stopwords'\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        exp = lr0 * 0.1**(epoch / s)\n",
    "        tf.summary.scalar('learning rate', data=exp, step=epoch)\n",
    "        return exp\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=10)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"./logged_models/\" + model_name + '/' + model_variant)\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_log_dir = get_run_logdir()\n",
    "file_writer = tf.summary.create_file_writer(run_log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_log_dir)\n",
    "\n",
    "mcp_save = callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "my_callbacks = [earlystopping, lr_scheduler, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 390, 64)           7924992   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 390, 64)           33024     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 390, 21)           1365      \n",
      "=================================================================\n",
      "Total params: 7,959,381\n",
      "Trainable params: 7,959,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 734/8621 [=>............................] - ETA: 45:16 - loss: 0.0236 - accuracy: 0.9958"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21120/2721761517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_polarities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifiers/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_variant\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Borrowed from: https://towardsdatascience.com/a-complete-step-by-step-tutorial-on-sentiment-analysis-in-keras-and-tensorflow-ea420cc8913f\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "input_dim = len(word_vocab)+1\n",
    "embedding_dim = 64\n",
    "output_dim = 64\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim, input_length=max_length),\n",
    "        layers.LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "        layers.TimeDistributed(layers.Dense(len(polarity_range), activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy']) # cross entropy loss chapter 4 HOML - categorial crossentropy because to_categorial \n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "history = model.fit(train_tokens, np.array(train_polarities), epochs=num_epochs, callbacks =[earlystopping, lr_scheduler, tensorboard_cb], validation_split=0.2)\n",
    "model.save('classifiers/' + model_name + '/' + model_variant + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 10  5 10 10 10  9 10 10  8 10 14 10  9 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10] [10 10  5 10 10 10  9 10 10  8 10 14 10  9 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1332x756 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import chain\n",
    "\n",
    "y_classes = y_pred.argmax(axis=-1)\n",
    "cm_true = np.array(test_polarities).argmax(axis=-1).flatten()\n",
    "cm_pred = y_classes.flatten()\n",
    "\n",
    "#cm_true = [x - 10 for x in cm_true]\n",
    "#cm_pred = [x - 10 for x in cm_pred]\n",
    "\n",
    "\n",
    "print(cm_true[:30], cm_pred[:30])\n",
    "\n",
    "\n",
    "cm = confusion_matrix(cm_true, cm_pred, normalize='pred')\n",
    "\n",
    "print(cm[0])\n",
    "\n",
    "fig = plt.figure( figsize=[18.5,10.5])\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "ax.set_xlabel('Predicted sentiment', fontsize = 15, labelpad=15.0)\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.set_ylabel('True sentiment', fontsize = 15, labelpad=15.0)\n",
    "ax.set_title('Multiclass sentiment analysis ranging from -1 to 1',fontweight=\"bold\", size=20, pad=100.0)\n",
    "\n",
    "conf_x = []\n",
    "\n",
    "temp = set(chain(*df['Polarity_rounded']))\n",
    "\n",
    "for i in temp:\n",
    "    conf_x.append(i)\n",
    "\n",
    "print(sorted(conf_x))\n",
    "\n",
    "cm_axis_vals = []\n",
    "\n",
    "for x in np.unique(np.array(cm_pred)):\n",
    "    cm_axis_vals.append(rep_to_pol[x])\n",
    "\n",
    "\n",
    "fig.colorbar(cax)\n",
    "plt.xticks(range(len(cm[0])),cm_axis_vals, rotation=90)\n",
    "plt.yticks(range(len(cm[0])), cm_axis_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rasmu\\anaconda3\\envs\\LA\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\Rasmu\\AppData\\Local\\Temp/ipykernel_16468/826983249.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_perf_2['f1-score'] = df_perf_2['f1-score'].round(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>10424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>210000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Polarity  precision  recall  f1-score   support\n",
       "0          3       1.00    1.00      1.00      82.0\n",
       "1          5       0.99    0.99      0.99     773.0\n",
       "2          6       0.99    0.99      0.99     704.0\n",
       "3          7       1.00    0.99      0.99    1082.0\n",
       "4          8       0.99    0.98      0.99    2816.0\n",
       "5          9       0.96    0.97      0.96   10424.0\n",
       "6         10       1.00    1.00      1.00  210000.0\n",
       "7         11       0.98    0.95      0.97    1534.0\n",
       "8         12       1.00    0.98      0.99     503.0\n",
       "9         13       0.98    0.97      0.98     190.0\n",
       "10        14       0.99    1.00      0.99     423.0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(cm_true, cm_pred, output_dict=True)\n",
    "df_perf = pd.DataFrame.from_dict(report).transpose()\n",
    "df_perf_2 = df_perf[:11]\n",
    "df_perf_2.insert(loc=0, column='Polarity', value=conf_x)\n",
    "df_perf_2.precision = df_perf_2.precision.round(2)\n",
    "df_perf_2.recall = df_perf_2.recall.round(2)\n",
    "df_perf_2['f1-score'] = df_perf_2['f1-score'].round(2)\n",
    "df_perf_2.support = df_perf_2.support.round()\n",
    "df_perf_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "df_perf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ce0bbaaba556c243eee45087b7684ce43fda2aa9a5b0798832d1be21bf73af7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
